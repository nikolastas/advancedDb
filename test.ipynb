{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mKernel Python 3.10.6 is not usable. Check the Jupyter output tab for more information. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/18 21:59:38 WARN Utils: Your hostname, Nikolass-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 10.3.24.19 instead (on interface en0)\n",
      "22/12/18 21:59:38 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/18 21:59:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/12/18 21:59:39 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyspark as ps\n",
    "sc = ps.SparkContext()\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"MyApp\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "locationIdToName = \"./taxi+_zone_lookup.csv\"\n",
    "taxis = \"./taxis\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "|         6|Staten Island|Arrochar/Fort Wad...|   Boro Zone|\n",
      "|         7|       Queens|             Astoria|   Boro Zone|\n",
      "|         8|       Queens|        Astoria Park|   Boro Zone|\n",
      "|         9|       Queens|          Auburndale|   Boro Zone|\n",
      "|        10|       Queens|        Baisley Park|   Boro Zone|\n",
      "|        11|     Brooklyn|          Bath Beach|   Boro Zone|\n",
      "|        12|    Manhattan|        Battery Park| Yellow Zone|\n",
      "|        13|    Manhattan|   Battery Park City| Yellow Zone|\n",
      "|        14|     Brooklyn|           Bay Ridge|   Boro Zone|\n",
      "|        15|       Queens|Bay Terrace/Fort ...|   Boro Zone|\n",
      "|        16|       Queens|             Bayside|   Boro Zone|\n",
      "|        17|     Brooklyn|             Bedford|   Boro Zone|\n",
      "|        18|        Bronx|        Bedford Park|   Boro Zone|\n",
      "|        19|       Queens|           Bellerose|   Boro Zone|\n",
      "|        20|        Bronx|             Belmont|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a rdd file from the csv file using pyspark\n",
    "dff_locactions = spark.read.csv(locationIdToName, header=True, inferSchema=True)\n",
    "dff_locactions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|       1| 2022-03-01 02:13:08|  2022-03-01 02:24:35|            1.0|          2.4|       1.0|                 N|          90|         209|           2|       10.0|  3.0|    0.5|       0.0|         0.0|                  0.3|        13.8|                 2.5|        0.0|\n",
      "|       1| 2022-03-01 02:47:52|  2022-03-01 03:00:08|            1.0|          2.2|       1.0|                 N|         148|         234|           2|       10.5|  3.0|    0.5|       0.0|         0.0|                  0.3|        14.3|                 2.5|        0.0|\n",
      "|       2| 2022-03-01 02:02:46|  2022-03-01 02:46:43|            1.0|        19.78|       2.0|                 N|         132|         249|           1|       52.0|  0.0|    0.5|     11.06|         0.0|                  0.3|       67.61|                 2.5|       1.25|\n",
      "|       2| 2022-03-01 02:52:43|  2022-03-01 03:03:40|            2.0|         2.94|       1.0|                 N|         211|          66|           1|       11.0|  0.5|    0.5|      4.44|         0.0|                  0.3|       19.24|                 2.5|        0.0|\n",
      "|       2| 2022-03-01 02:15:35|  2022-03-01 02:34:13|            1.0|         8.57|       1.0|                 N|         138|         197|           1|       25.0|  0.5|    0.5|      5.51|         0.0|                  0.3|       33.06|                 0.0|       1.25|\n",
      "|       1| 2022-03-01 02:11:57|  2022-03-01 02:53:05|            2.0|         14.0|       1.0|                 N|         132|          33|           1|       43.5| 1.75|    0.5|       9.2|         0.0|                  0.3|       55.25|                 0.0|       1.25|\n",
      "|       2| 2022-03-01 02:05:11|  2022-03-01 02:08:22|            1.0|         0.61|       1.0|                 N|         166|         151|           1|        4.5|  0.5|    0.5|       1.0|         0.0|                  0.3|         6.8|                 0.0|        0.0|\n",
      "|       2| 2022-03-01 02:30:56|  2022-03-01 02:46:21|            1.0|         2.83|       1.0|                 N|          74|         238|           1|       13.0|  0.5|    0.5|       3.7|         0.0|                  0.3|        18.0|                 0.0|        0.0|\n",
      "|       2| 2022-03-01 02:30:28|  2022-03-01 02:30:36|            1.0|          0.1|       1.0|                 N|         145|         145|           3|       -2.5| -0.5|   -0.5|       0.0|         0.0|                 -0.3|        -3.8|                 0.0|        0.0|\n",
      "|       2| 2022-03-01 02:30:28|  2022-03-01 02:30:36|            1.0|          0.1|       1.0|                 N|         145|         145|           2|        2.5|  0.5|    0.5|       0.0|         0.0|                  0.3|         3.8|                 0.0|        0.0|\n",
      "|       2| 2022-03-01 02:34:25|  2022-03-01 02:39:43|            1.0|          1.4|       2.0|                 N|         170|          90|           1|       52.0|  0.0|    0.5|       8.0|        6.55|                  0.3|       69.85|                 2.5|        0.0|\n",
      "|       2| 2022-03-01 02:35:11|  2022-03-01 03:20:33|            1.0|        14.48|       1.0|                 N|         132|          97|           1|       45.5|  0.5|    0.5|      9.36|         0.0|                  0.3|       57.41|                 0.0|       1.25|\n",
      "|       2| 2022-03-01 02:59:02|  2022-03-01 03:13:38|            1.0|         7.98|       1.0|                 N|         138|         255|           1|       23.5|  0.5|    0.5|       4.0|         0.0|                  0.3|       30.05|                 0.0|       1.25|\n",
      "|       2| 2022-03-01 02:16:00|  2022-03-01 02:36:46|            1.0|         3.48|       1.0|                 N|         179|         226|           2|       16.0|  0.5|    0.5|       0.0|         0.0|                  0.3|        17.3|                 0.0|        0.0|\n",
      "|       2| 2022-03-01 02:57:18|  2022-03-01 03:38:31|            1.0|         8.57|       1.0|                 N|         226|          70|           2|       34.0|  0.5|    0.5|       0.0|         0.0|                  0.3|        35.3|                 0.0|        0.0|\n",
      "|       2| 2022-03-01 02:01:50|  2022-03-01 02:17:53|            1.0|         7.56|       1.0|                 N|         138|         256|           1|       23.5|  0.5|    0.5|       6.2|         0.0|                  0.3|       32.25|                 0.0|       1.25|\n",
      "|       2| 2022-03-01 03:03:05|  2022-03-01 03:06:05|            5.0|         0.62|       1.0|                 N|          80|         255|           2|        4.5|  0.5|    0.5|       0.0|         0.0|                  0.3|         5.8|                 0.0|        0.0|\n",
      "|       2| 2022-03-01 02:28:14|  2022-03-01 02:43:11|            2.0|         4.33|       1.0|                 N|         211|         142|           1|       15.0|  0.5|    0.5|      3.76|         0.0|                  0.3|       22.56|                 2.5|        0.0|\n",
      "|       2| 2022-03-01 02:35:49|  2022-03-01 03:14:54|            1.0|        20.76|       2.0|                 N|         132|         238|           1|       52.0|  0.0|    0.5|     12.12|        6.55|                  0.3|       72.72|                 0.0|       1.25|\n",
      "|       2| 2022-03-01 02:22:31|  2022-03-01 02:30:49|            2.0|         1.45|       1.0|                 N|         148|         231|           1|        7.5|  0.5|    0.5|      2.26|         0.0|                  0.3|       13.56|                 2.5|        0.0|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a rdd file from the parquet file using pyspark\n",
    "dff_taxis = spark.read.parquet(taxis)\n",
    "dff_taxis.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a view for taxis \n",
    "dff_taxis.createOrReplaceTempView(\"taxis\")\n",
    "# do the same for locations\n",
    "dff_locactions.createOrReplaceTempView(\"locations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:===================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(VendorID=2, tpep_pickup_datetime=datetime.datetime(2022, 3, 17, 12, 27, 47), tpep_dropoff_datetime=datetime.datetime(2022, 3, 17, 12, 27, 58), passenger_count=1.0, trip_distance=0.0, RatecodeID=1.0, store_and_fwd_flag='N', PULocationID=12, DOLocationID=12, payment_type=1, fare_amount=2.5, extra=0.0, mta_tax=0.5, tip_amount=40.0, tolls_amount=0.0, improvement_surcharge=0.3, total_amount=45.8, congestion_surcharge=2.5, airport_fee=0.0, LocationID=12, Borough='Manhattan', Zone='Battery Park', service_zone='Yellow Zone')]\n",
      "Time:  2.67386794090271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "# lets filter all taxis trips , that happend in march\n",
    "marchTrips = spark.sql(\n",
    "  \"\"\"\n",
    "  SELECT *\n",
    "  FROM taxis \n",
    "  INNER JOIN locations ON taxis.DOLocationID = locations.LocationID\n",
    "  WHERE tpep_pickup_datetime >= '2022-03-01' \n",
    "  AND tpep_pickup_datetime < '2022-04-01' and tpep_dropoff_datetime >= '2022-03-01' \n",
    "  AND tpep_dropoff_datetime < '2022-04-01'\n",
    "  AND locations.Zone = \"Battery Park\"\n",
    "  ORDER BY Tip_amount DESC\n",
    "  limit 1\n",
    "  \"\"\"\n",
    "  )\n",
    "\n",
    "bestTipTripMarch = ((marchTrips).collect())\n",
    "end = time.time()\n",
    "print(bestTipTripMarch)\n",
    "print('Time: ',end - start)\n",
    "\n",
    "# filter the previus trips that "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:==============>                                            (2 + 6) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(max_toll_fees_per_month=193.3, month=1), Row(max_toll_fees_per_month=235.7, month=3), Row(max_toll_fees_per_month=911.87, month=4), Row(max_toll_fees_per_month=95.0, month=2), Row(max_toll_fees_per_month=800.09, month=6), Row(max_toll_fees_per_month=29.55, month=7), Row(max_toll_fees_per_month=18.3, month=10), Row(max_toll_fees_per_month=813.75, month=5)]\n",
      "Time:  1.1666901111602783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "highestTollFees = spark.sql(\n",
    "  \"\"\"\n",
    "  SELECT MAX(Tolls_amount) as max_toll_fees_per_month, MONTH(tpep_pickup_datetime) as month\n",
    "  FROM taxis\n",
    "  where Tolls_amount > 0\n",
    "  GROUP BY MONTH(tpep_pickup_datetime)\n",
    "  \"\"\"\n",
    "  )\n",
    "highestTollFees = ((highestTollFees).collect())\n",
    "end = time.time()\n",
    "print(highestTollFees)\n",
    "print('Time: ',end - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
