{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mKernel Python 3.10.6 is not usable. Check the Jupyter output tab for more information. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/18 21:59:38 WARN Utils: Your hostname, Nikolass-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 10.3.24.19 instead (on interface en0)\n",
      "22/12/18 21:59:38 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/18 21:59:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/12/18 21:59:39 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyspark as ps\n",
    "sc = ps.SparkContext()\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"MyApp\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "locationIdToName = \"./taxi+_zone_lookup.csv\"\n",
    "taxis = \"./taxis\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "|         6|Staten Island|Arrochar/Fort Wad...|   Boro Zone|\n",
      "|         7|       Queens|             Astoria|   Boro Zone|\n",
      "|         8|       Queens|        Astoria Park|   Boro Zone|\n",
      "|         9|       Queens|          Auburndale|   Boro Zone|\n",
      "|        10|       Queens|        Baisley Park|   Boro Zone|\n",
      "|        11|     Brooklyn|          Bath Beach|   Boro Zone|\n",
      "|        12|    Manhattan|        Battery Park| Yellow Zone|\n",
      "|        13|    Manhattan|   Battery Park City| Yellow Zone|\n",
      "|        14|     Brooklyn|           Bay Ridge|   Boro Zone|\n",
      "|        15|       Queens|Bay Terrace/Fort ...|   Boro Zone|\n",
      "|        16|       Queens|             Bayside|   Boro Zone|\n",
      "|        17|     Brooklyn|             Bedford|   Boro Zone|\n",
      "|        18|        Bronx|        Bedford Park|   Boro Zone|\n",
      "|        19|       Queens|           Bellerose|   Boro Zone|\n",
      "|        20|        Bronx|             Belmont|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a rdd file from the csv file using pyspark\n",
    "dff_locactions = spark.read.csv(locationIdToName, header=True, inferSchema=True)\n",
    "dff_locactions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|       1| 2022-03-01 02:13:08|  2022-03-01 02:24:35|            1.0|          2.4|       1.0|                 N|          90|         209|           2|       10.0|  3.0|    0.5|       0.0|         0.0|                  0.3|        13.8|                 2.5|        0.0|\n",
      "|       1| 2022-03-01 02:47:52|  2022-03-01 03:00:08|            1.0|          2.2|       1.0|                 N|         148|         234|           2|       10.5|  3.0|    0.5|       0.0|         0.0|                  0.3|        14.3|                 2.5|        0.0|\n",
      "|       2| 2022-03-01 02:02:46|  2022-03-01 02:46:43|            1.0|        19.78|       2.0|                 N|         132|         249|           1|       52.0|  0.0|    0.5|     11.06|         0.0|                  0.3|       67.61|                 2.5|       1.25|\n",
      "|       2| 2022-03-01 02:52:43|  2022-03-01 03:03:40|            2.0|         2.94|       1.0|                 N|         211|          66|           1|       11.0|  0.5|    0.5|      4.44|         0.0|                  0.3|       19.24|                 2.5|        0.0|\n",
      "|       2| 2022-03-01 02:15:35|  2022-03-01 02:34:13|            1.0|         8.57|       1.0|                 N|         138|         197|           1|       25.0|  0.5|    0.5|      5.51|         0.0|                  0.3|       33.06|                 0.0|       1.25|\n",
      "|       1| 2022-03-01 02:11:57|  2022-03-01 02:53:05|            2.0|         14.0|       1.0|                 N|         132|          33|           1|       43.5| 1.75|    0.5|       9.2|         0.0|                  0.3|       55.25|                 0.0|       1.25|\n",
      "|       2| 2022-03-01 02:05:11|  2022-03-01 02:08:22|            1.0|         0.61|       1.0|                 N|         166|         151|           1|        4.5|  0.5|    0.5|       1.0|         0.0|                  0.3|         6.8|                 0.0|        0.0|\n",
      "|       2| 2022-03-01 02:30:56|  2022-03-01 02:46:21|            1.0|         2.83|       1.0|                 N|          74|         238|           1|       13.0|  0.5|    0.5|       3.7|         0.0|                  0.3|        18.0|                 0.0|        0.0|\n",
      "|       2| 2022-03-01 02:30:28|  2022-03-01 02:30:36|            1.0|          0.1|       1.0|                 N|         145|         145|           3|       -2.5| -0.5|   -0.5|       0.0|         0.0|                 -0.3|        -3.8|                 0.0|        0.0|\n",
      "|       2| 2022-03-01 02:30:28|  2022-03-01 02:30:36|            1.0|          0.1|       1.0|                 N|         145|         145|           2|        2.5|  0.5|    0.5|       0.0|         0.0|                  0.3|         3.8|                 0.0|        0.0|\n",
      "|       2| 2022-03-01 02:34:25|  2022-03-01 02:39:43|            1.0|          1.4|       2.0|                 N|         170|          90|           1|       52.0|  0.0|    0.5|       8.0|        6.55|                  0.3|       69.85|                 2.5|        0.0|\n",
      "|       2| 2022-03-01 02:35:11|  2022-03-01 03:20:33|            1.0|        14.48|       1.0|                 N|         132|          97|           1|       45.5|  0.5|    0.5|      9.36|         0.0|                  0.3|       57.41|                 0.0|       1.25|\n",
      "|       2| 2022-03-01 02:59:02|  2022-03-01 03:13:38|            1.0|         7.98|       1.0|                 N|         138|         255|           1|       23.5|  0.5|    0.5|       4.0|         0.0|                  0.3|       30.05|                 0.0|       1.25|\n",
      "|       2| 2022-03-01 02:16:00|  2022-03-01 02:36:46|            1.0|         3.48|       1.0|                 N|         179|         226|           2|       16.0|  0.5|    0.5|       0.0|         0.0|                  0.3|        17.3|                 0.0|        0.0|\n",
      "|       2| 2022-03-01 02:57:18|  2022-03-01 03:38:31|            1.0|         8.57|       1.0|                 N|         226|          70|           2|       34.0|  0.5|    0.5|       0.0|         0.0|                  0.3|        35.3|                 0.0|        0.0|\n",
      "|       2| 2022-03-01 02:01:50|  2022-03-01 02:17:53|            1.0|         7.56|       1.0|                 N|         138|         256|           1|       23.5|  0.5|    0.5|       6.2|         0.0|                  0.3|       32.25|                 0.0|       1.25|\n",
      "|       2| 2022-03-01 03:03:05|  2022-03-01 03:06:05|            5.0|         0.62|       1.0|                 N|          80|         255|           2|        4.5|  0.5|    0.5|       0.0|         0.0|                  0.3|         5.8|                 0.0|        0.0|\n",
      "|       2| 2022-03-01 02:28:14|  2022-03-01 02:43:11|            2.0|         4.33|       1.0|                 N|         211|         142|           1|       15.0|  0.5|    0.5|      3.76|         0.0|                  0.3|       22.56|                 2.5|        0.0|\n",
      "|       2| 2022-03-01 02:35:49|  2022-03-01 03:14:54|            1.0|        20.76|       2.0|                 N|         132|         238|           1|       52.0|  0.0|    0.5|     12.12|        6.55|                  0.3|       72.72|                 0.0|       1.25|\n",
      "|       2| 2022-03-01 02:22:31|  2022-03-01 02:30:49|            2.0|         1.45|       1.0|                 N|         148|         231|           1|        7.5|  0.5|    0.5|      2.26|         0.0|                  0.3|       13.56|                 2.5|        0.0|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a rdd file from the parquet file using pyspark\n",
    "dff_taxis = spark.read.parquet(taxis)\n",
    "dff_taxis.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a view for taxis \n",
    "dff_taxis.createOrReplaceTempView(\"taxis\")\n",
    "# do the same for locations\n",
    "dff_locactions.createOrReplaceTempView(\"locations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:===================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(VendorID=2, tpep_pickup_datetime=datetime.datetime(2022, 3, 17, 12, 27, 47), tpep_dropoff_datetime=datetime.datetime(2022, 3, 17, 12, 27, 58), passenger_count=1.0, trip_distance=0.0, RatecodeID=1.0, store_and_fwd_flag='N', PULocationID=12, DOLocationID=12, payment_type=1, fare_amount=2.5, extra=0.0, mta_tax=0.5, tip_amount=40.0, tolls_amount=0.0, improvement_surcharge=0.3, total_amount=45.8, congestion_surcharge=2.5, airport_fee=0.0, LocationID=12, Borough='Manhattan', Zone='Battery Park', service_zone='Yellow Zone')]\n",
      "Time:  2.67386794090271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "# lets filter all taxis trips , that happend in march\n",
    "marchTrips = spark.sql(\n",
    "  \"\"\"\n",
    "  SELECT *\n",
    "  FROM taxis \n",
    "  INNER JOIN locations ON taxis.DOLocationID = locations.LocationID\n",
    "  WHERE tpep_pickup_datetime >= '2022-03-01' \n",
    "  AND tpep_pickup_datetime < '2022-04-01' and tpep_dropoff_datetime >= '2022-03-01' \n",
    "  AND tpep_dropoff_datetime < '2022-04-01'\n",
    "  AND locations.Zone = \"Battery Park\"\n",
    "  ORDER BY Tip_amount DESC\n",
    "  limit 1\n",
    "  \"\"\"\n",
    "  )\n",
    "\n",
    "bestTipTripMarch = ((marchTrips).collect())\n",
    "end = time.time()\n",
    "print(bestTipTripMarch)\n",
    "print('Time: ',end - start)\n",
    "\n",
    "# filter the previus trips that "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(max_toll_fees_per_month=235.7, month=3, max_date=datetime.datetime(2022, 3, 31, 23, 59, 50)), Row(max_toll_fees_per_month=911.87, month=4, max_date=datetime.datetime(2022, 4, 30, 23, 59, 39)), Row(max_toll_fees_per_month=95.0, month=2, max_date=datetime.datetime(2022, 2, 28, 23, 59, 55)), Row(max_toll_fees_per_month=800.09, month=6, max_date=datetime.datetime(2022, 6, 30, 23, 59, 52)), Row(max_toll_fees_per_month=29.55, month=7, max_date=datetime.datetime(2022, 7, 1, 2, 59, 49)), Row(max_toll_fees_per_month=813.75, month=5, max_date=datetime.datetime(2022, 5, 31, 23, 59, 55)), Row(max_toll_fees_per_month=193.3, month=1, max_date=datetime.datetime(2022, 1, 31, 23, 59, 48))]\n",
      "Time:  0.680427074432373\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "highestTollFees = spark.sql(\n",
    "  \"\"\"\n",
    "  SELECT MAX(Tolls_amount) as max_toll_fees_per_month, MONTH(tpep_pickup_datetime) as month, \n",
    "  MAX(tpep_pickup_datetime) as max_date\n",
    "  FROM taxis\n",
    "  where Tolls_amount > 0\n",
    "  AND YEAR(tpep_pickup_datetime) = '2022'\n",
    "  GROUP BY MONTH(tpep_pickup_datetime)\n",
    "  \"\"\"\n",
    "  )\n",
    "highestTollFees = ((highestTollFees).collect())\n",
    "end = time.time()\n",
    "print(highestTollFees)\n",
    "print('Time: ',end - start)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 54:====================================>                     (5 + 3) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(avg_trip_distance=3.8276608700743653, avg_trip_cost=21.701845541305357, period=datetime.datetime(2022, 7, 1, 0, 0)), Row(avg_trip_distance=5.9169746181557965, avg_trip_cost=22.067763372211772, period=datetime.datetime(2022, 6, 16, 0, 0)), Row(avg_trip_distance=6.0802899985688335, avg_trip_cost=22.172336874148503, period=datetime.datetime(2022, 6, 1, 0, 0)), Row(avg_trip_distance=7.569369040277797, avg_trip_cost=22.491229166374467, period=datetime.datetime(2022, 5, 16, 0, 0)), Row(avg_trip_distance=6.057147110233409, avg_trip_cost=21.63975255180099, period=datetime.datetime(2022, 5, 1, 0, 0)), Row(avg_trip_distance=5.776266087061577, avg_trip_cost=21.163756511111103, period=datetime.datetime(2022, 4, 16, 0, 0)), Row(avg_trip_distance=5.569090353516405, avg_trip_cost=21.22049664355691, period=datetime.datetime(2022, 4, 1, 0, 0)), Row(avg_trip_distance=5.377357732415769, avg_trip_cost=20.827389869581747, period=datetime.datetime(2022, 3, 16, 0, 0)), Row(avg_trip_distance=6.198273223613596, avg_trip_cost=20.341253580632934, period=datetime.datetime(2022, 3, 1, 0, 0)), Row(avg_trip_distance=5.66965409358638, avg_trip_cost=19.872534137277956, period=datetime.datetime(2022, 2, 16, 0, 0)), Row(avg_trip_distance=6.016623620021893, avg_trip_cost=19.154479384660576, period=datetime.datetime(2022, 2, 1, 0, 0)), Row(avg_trip_distance=5.3369039394970885, avg_trip_cost=18.817965882906936, period=datetime.datetime(2022, 1, 16, 0, 0)), Row(avg_trip_distance=5.4202367328412, avg_trip_cost=19.56788592618281, period=datetime.datetime(2022, 1, 1, 0, 0))]\n",
      "Time:  2.246509075164795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# group by every 15 days and find the average trip distance and the average trip cost\n",
    "start = time.time()\n",
    "avgTripDistanceAndCost = spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT AVG(Trip_distance) as avg_trip_distance, AVG(Total_amount) as avg_trip_cost,\n",
    "    CASE \n",
    "        WHEN \n",
    "            EXTRACT(day FROM tpep_pickup_datetime) BETWEEN 1 AND 15 \n",
    "            THEN DATE_TRUNC('month', tpep_pickup_datetime)\n",
    "        ELSE DATE_ADD(DATE_TRUNC('month', tpep_pickup_datetime), 15)\n",
    "    END AS period\n",
    "    FROM taxis\n",
    "    WHERE tpep_pickup_datetime >= '2022-01-01'\n",
    "    AND tpep_pickup_datetime < '2022-12-31'\n",
    "    GROUP BY period\n",
    "    ORDER BY period DESC\n",
    "    \"\"\"\n",
    "    )\n",
    "avgTripDistanceAndCost = ((avgTripDistanceAndCost).collect())\n",
    "end = time.time()\n",
    "print(avgTripDistanceAndCost)\n",
    "print('Time: ',end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MapPartitionsRDD[139] at javaToPython at DirectMethodHandleAccessor.java:104\n"
     ]
    }
   ],
   "source": [
    "rdd_taxis = dff_taxis.rdd\n",
    "rdd_locations = dff_locactions.rdd\n",
    "print(rdd_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 63:==============>                                           (2 + 6) / 8]\r"
     ]
    }
   ],
   "source": [
    "# do the same but in rdd format\n",
    "start = time.time()\n",
    "avgTripDistanceAndCostRdd = rdd_taxis.map(lambda x: (int(x.total_amount)) )\n",
    "\n",
    "for i in avgTripDistanceAndCostRdd.collect():\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
